--- 
- import_playbook: tasks/check_all.yml



- name: Check OpenShift deployment status
  hosts: openshift_clusters
  gather_facts: false
  vars_files:
  - passwords/ansible_vault.yml
  - vars/network-config.yml
  - group_vars/vcenter_vms.yml
  environment:
    KUBECONFIG: "{{ vars.openshift_config_dir }}/auth/kubeconfig"
  tasks:

  - name: Combine customized VM config
    set_fact:
      community_vmware_vmware__guest: "{{ default_community_vmware_vmware__guest | combine(custom_community_vmware_vmware__guest | default({}), recursive=true) }}"
      ansible_becomes_password: "{{ client_password }}"
    tags: always

  - name: Gather hostvars as dict
    set_fact:
      hostvars_dict: "{{ hostvars }}"
    tags: always

  - name: Check whether OpenShift cluster exists already
    tags: always
    delegate_to: localhost
    block:

    - name: Check whether OpenShift cluster exists already
      kubernetes.core.k8s_info:
        api_version: v1
        kind: Namespace
        name: openshift-kube-apiserver
      register: namespace_kube_apiserver
      timeout: 10
      retries: 3
      ignore_errors: yes

    - name: "Halt when namespace 'openshift-kube-apiserver' does not already exists"
      fail:
        msg: "Namespace 'openshift-kube-apiserver' does not already exists, deploy it first!"
      when:  namespace_kube_apiserver.failed or namespace_kube_apiserver.resources[0].status.phase | default('') != "Active"

  - name: Deploy pre-reqs
    delegate_to: localhost
    block:

    - name: Deploy DHCP reservations
      ansible.builtin.import_tasks: tasks/deploy-windows-dhcp-reservations.yml
      tags: deploy_infrastructure_dhcp
      
    - name: Deploy NSX segments
      ansible.builtin.include_tasks:
        file: tasks/deploy-vmware-nsx-segments.yml
        apply:
          tags: vm
      tags: vm, deploy_nsx_segments
      vars:
        ansible_python_interpreter: /usr/bin/python3.9
      when: nsx_integration
      

- name: Deploy the storage nodes
  hosts: openshift_storage_nodes
  gather_facts: false
  vars_files:
  - passwords/ansible_vault.yml
  - vars/network-config.yml
  - group_vars/vcenter_vms.yml
  environment:
    KUBECONFIG: "{{ vars.openshift_config_dir }}/auth/kubeconfig"
  tasks:

  - name: Deploy VMs
    tags: vm
    ansible.builtin.include_tasks:
      file: tasks/deploy-vmware-vms-from-template.yml
      apply:
        tags: vm

- name: Deploy ignition configs on storage nodes
  hosts: openshift_storage_nodes
  gather_facts: false
  vars_files:
  - passwords/ansible_vault.yml
  - vars/network-config.yml
  tasks:

  - name: Prepare nodes
    # when: vars.namespace_kube_apiserver.failed or (vars.namespace_kube_apiserver.resources is defined and vars.namespace_kube_apiserver.resources | length != 0 and vars.namespace_kube_apiserver.resources[0].status.phase != "Active")
    tags: prep_nodes
    block:

    - name: Update VMs' Advanced Settings with Base64 encoded ignition data
      throttle: "{{ parallel_deployments }}"
      retries: 3
      delay: 10
      community.vmware.vmware_guest:
        validate_certs: "{{ validate_certs | default(false) }}"
        hostname: "{{ vcenter_hostname | default(lookup('env', 'VMWARE_HOST')) }}"
        username: "{{ vcenter_username | default(lookup('env', 'VMWARE_USER')) }}"
        password: "{{ vcenter_password | default(lookup('env', 'VMWARE_PASSWORD')) }}"
        name: "{{ inventory_hostname_short }}"
        state: present
        advanced_settings:
        - key: guestinfo.ignition.config.data
          value: "{{ lookup('file', '{{ vars.openshift_config_dir }}/worker.ign') | b64encode }}"

      delegate_to: localhost
      tags: ignition_vm_deploy
      with_items:
      - "storage"

- name: Power on storage nodes
  hosts: openshift_storage_nodes
  gather_facts: false
  vars_files:
  - passwords/ansible_vault.yml
  - vars/network-config.yml
  tasks:

  - name: Start the storage nodes if bootstrap is needed
    # when: vars.namespace_kube_apiserver.failed or (vars.namespace_kube_apiserver.resources is defined and vars.namespace_kube_apiserver.resources | length != 0 and vars.namespace_kube_apiserver.resources[0].status.phase != "Active")
    tags: deploy_cluster
    block:

    - name: Power on storage nodes if bootstrap is needed
      retries: 3
      delay: 10
      community.vmware.vmware_guest:
        validate_certs: "{{ validate_certs | default(false) }}"
        hostname: "{{ vcenter_hostname | default(lookup('env', 'VMWARE_HOST')) }}"
        username: "{{ vcenter_username | default(lookup('env', 'VMWARE_USER')) }}"
        password: "{{ vcenter_password | default(lookup('env', 'VMWARE_PASSWORD')) }}"
        name: "{{ inventory_hostname_short }}"
        state: poweredon
      delegate_to: localhost

- name: Deploy dedicated OpenShift storage nodes
  hosts: openshift_bootstrap_nodes
  gather_facts: false
  vars_files:
  - passwords/ansible_vault.yml
  - vars/network-config.yml
  - group_vars/vcenter_vms.yml
  environment:
    KUBECONFIG: "{{ vars.openshift_config_dir }}/auth/kubeconfig"
  tasks:

  - name: Deploy storage nodes
    tags: deploy_cluster_storage
    delegate_to: localhost
    block:

    - name: 'Set # of nodes to wait for'
      set_fact:
        number_of_ready_nodes: "{{ 0 +
          hostvars_dict.values()
            | selectattr('openshift_cluster_name', 'defined')
            | selectattr('openshift_cluster_name', 'eq', vars.openshift_cluster_name)
            | selectattr('type', 'eq', 'master')
            | map(attribute='ip')
            | list | length | int +
          hostvars_dict.values()
            | selectattr('openshift_cluster_name', 'defined')
            | selectattr('openshift_cluster_name', 'eq', vars.openshift_cluster_name)
            | selectattr('type', 'eq', 'worker')
            | map(attribute='ip')
            | list | length | int +
          hostvars_dict.values()
            | selectattr('openshift_cluster_name', 'defined')
            | selectattr('openshift_cluster_name', 'eq', vars.openshift_cluster_name)
            | selectattr('type', 'eq', 'infra')
            | map(attribute='ip')
            | list | length | int +
          hostvars_dict.values()
            | selectattr('openshift_cluster_name', 'defined')
            | selectattr('openshift_cluster_name', 'eq', vars.openshift_cluster_name)
            | selectattr('type', 'eq', 'storage')
            | map(attribute='ip')
            | list | length | int }}"

    - name: Accept storage node bootstrap & node serving CSRs
      ansible.builtin.include_tasks: tasks/deploy_openshift_accept_csr_till_all_nodes_ready.yml
    
    - name: Mark storage nodes unschedulable with a proper taint
      kubernetes.core.k8s:
        api_version: v1
        definition:
          api_version: v1
          kind: Node
          metadata:
            name: "{{ hostvars[item].inventory_hostname_short }}"
            labels:
              node-role.kubernetes.io/worker: ""
              node-role.kubernetes.io/infra: ""
              cluster.ocs.openshift.io/openshift-storage: ""
          spec:
            taints:
            - effect: NoSchedule
              key: node.ocs.openshift.io/storage
              value: "true"
      when: hostvars[item].openshift_cluster_name == vars.openshift_cluster_name
      with_items: "{{ groups.openshift_storage_nodes }}"

    - name: List Nodes
      shell: oc get nodes
      register: cli_nodes_results

    - debug:
        msg: "{{ ['Nodes:'] + cli_nodes_results.stdout_lines }}"

    - name: List ClusterOperators
      shell: oc get co
      register: cli_co_results

    - debug:
        msg: "{{ ['ClusterOperators:'] + cli_co_results.stdout_lines }}"

    - name: Install OpenShift Data Foundation Operator
      include: tasks/deploy_openshift_operator_install.yml
      tags: onlyme
      vars:
        install_operator_action: install
        install_operator_name: "{{ vars.openshift_data_foundation_config.operator_name }}"
        install_operator_namespace: openshift-storage
        install_operator_catalog: redhat-operators
        install_operator_packagemanifest_name: "{{ vars.openshift_data_foundation_config.operator_name }}" #ocs-operator
        install_operator_csv_nameprefix: "{{ vars.openshift_data_foundation_config.operator_name }}" #ocs-operator
        install_operator_install_csv_ignore_error: false
        install_operator_channel: "{{ vars.openshift_data_foundation_config.operator_channel }}"
        install_operator_automatic_install_plan_approval: "{{ vars.openshift_data_foundation_config.operator_automatic_install_plan_approval | default(true) }}"
        install_operator_manage_namespaces:
        - "{{ vars.openshift_data_foundation_config.operator_manage_namespaces }}"
        install_operator_catalogsource_setup: "{{ operator_catalogsource_setup | default(false) }}"
        install_operator_catalogsource_name: "{{ operator_catalogsource_name | default('') }}"
        install_operator_catalogsource_image: "{{ operator_catalogsource_image | default('') }}"
        install_operator_catalogsource_image_tag: "{{ operator_catalogsource_image_tag | default('') }}"

    - name: Patch the installation to enable the CLI tools
      tags: deploy_tools
      delegate_to: localhost
      kubernetes.core.k8s_json_patch:
        api_version: ocs.openshift.io/v1
        namespace: openshift-storage
        kind: OCSInitialization
        name: ocsinit
        patch:
          - op: replace
            path: "/spec/enableCephTools"
            value: true

    - name: Get the current console plugins
      tags: deploy_plugin
      delegate_to: localhost
      kubernetes.core.k8s_info:
        api_version: operator.openshift.io/v1
        namespace: openshift-storage
        kind: Console
        name: cluster
      register: console_plugins

    - name: Patch the installation to enable the console plugin
      tags: deploy_plugin
      delegate_to: localhost
      vars:
        plugins: "{{ [] + (console_plugins.resources[0].spec.plugins | default ([])) + ['odf-console'] }}"
      kubernetes.core.k8s_json_patch:
        api_version: operator.openshift.io/v1
        namespace: openshift-storage
        kind: Console
        name: cluster
        patch:
          - op: add
            path: "/spec/plugins"
            value: "{{ plugins }}"
      when: not 'odf-console' in (console_plugins.resources[0].spec.plugins | default ([]))


    - name: Add an OpenShift Data Foundation StorageCluster
      vars:
        app_namespace: "{{ vars.openshift_data_foundation_config.operator_manage_namespaces }}"
        app_sc_name: "{{ vars.openshift_data_foundation_config.storage_system_name }}"
        osd_requests_cpu: "{{ vars.openshift_data_foundation_config.osd_requests_cpu }}"
        osd_requests_memory: "{{ vars.openshift_data_foundation_config.osd_requests_memory }}"
        osd_limits_cpu: "{{ vars.openshift_data_foundation_config.osd_limits_cpu }}"
        osd_limits_memory: "{{ vars.openshift_data_foundation_config.osd_limits_memory }}"
        osd_storageclassname: "{{ vars.openshift_data_foundation_config.osd_storageclassname }}"
        osd_requests_storage: "{{ vars.openshift_data_foundation_config.osd_requests_storage }}"
        mds_requests_cpu: "{{ vars.openshift_data_foundation_config.mds_requests_cpu }}"
        mds_requests_memory: "{{ vars.openshift_data_foundation_config.mds_requests_memory }}"
        mds_limits_cpu: "{{ vars.openshift_data_foundation_config.mds_limits_cpu }}"
        mds_limits_memory: "{{ vars.openshift_data_foundation_config.mds_limits_memory }}"
        rgw_requests_cpu: "{{ vars.openshift_data_foundation_config.rgw_requests_cpu }}"
        rgw_requests_memory: "{{ vars.openshift_data_foundation_config.rgw_requests_memory }}"
        rgw_limits_cpu: "{{ vars.openshift_data_foundation_config.rgw_limits_cpu }}"
        rgw_limits_memory: "{{ vars.openshift_data_foundation_config.rgw_limits_memory }}"
      block:

      - name: Create a cluster
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_storagecluster.yml'

        register: deploy_odf_cluster
        retries: 72
        delay: 10
        until:
          - deploy_odf_cluster.result.status.phase is defined
          - deploy_odf_cluster.result.status.phase | length > 0
          - deploy_odf_cluster.result.status.phase == 'Ready'


      - name: Remove thin as the default storage class
        tags: temp
        kubernetes.core.k8s:
          definition:
            kind: StorageClass
            apiVersion: storage.k8s.io/v1
            metadata:
              name: thin
              annotations:
                storageclass.kubernetes.io/is-default-class: 'false'
          state: present

      - name: Set CephFS as default storage class
        tags: temp
        kubernetes.core.k8s:
          definition:
            kind: StorageClass
            apiVersion: storage.k8s.io/v1
            metadata:
              name: "{{ vars.openshift_data_foundation_config.storage_system_name }}-cephfs"
              annotations:
                storageclass.kubernetes.io/is-default-class: 'true'
          state: present


  - name: Deploy example projects
    tags: deploy_example_all, deploy_example_ceph_rbd
    delegate_to: localhost
    block:

    - name: Nginx app through Ansible with ceph-rbd and block mode
      vars:
        app_name: nginx-rbd
        app_namespace: test-nginx-ceph-rbd-block-ansible
        app_container_source: nginxinc/nginx-unprivileged:latest
        app_service_port: 80
        app_service_protocol: tcp
        app_container_port: 8080
        app_replicas: 1 # More than 1 would require clustered FileSystem. RHEL supports GFS1&2, but as an add-on.
        app_pvc_name: "{{ app_name }}-pvc"
        app_pvc_accessmode: ReadWriteMany # ReadWriteOnce, ReadWriteMany, ReadOnlyMany, based on storageClass & volumeMode
        app_pvc_volumeMode: Block # Generally Block or Filesystem
        app_pvc_size: 1Gi
        app_pvc_storageClassName: "{{ vars.openshift_data_foundation_config.storage_system_name }}-ceph-rbd"
        app_volumeDevices:
        - name: "{{ app_name }}-pv"
          devicePath: /dev/xvdb
        app_volumes:
        - name: "{{ app_name }}-pv"
          persistentVolumeClaim:
            claimName: "{{ app_name }}-pvc"
        # app_initContainers:
        # If an FS is needed, then the idea would be to format it in an initContainer, but mounting requires root and a Service Account and something else, so we'll just go for a check with dd.
        # - name: format-volume
        #   image: registry.redhat.io/rhel7/rhel-tools
        #   command:
        #   - 'sh'
        #   - '-c'
        #   - 'mkfs.ext4 /dev/xvdb && mount /dev/xvdb /usr/share/nginx'
        #   deviceMounts:
        #   - name: "{{ app_name }}-pv"
        #     devicePath: /dev/xvdb
        #   securityContext:
        #     # privileged: True
        #     runAsUser: 0
        # app_sa_name: "{{ app_name }}-sa"
        # app_sa_scc: rook-ceph

      block:

      - name: Add namespace for Nginx with RBD app through Ansible  
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_namespace.yml'

      # - name: Add Service Account
      #   kubernetes.core.k8s:
      #     api_version: apps/v1
      #     template: 'templates/openshift_4_resource_serviceaccount.yml'

      # - name: Add SCC to  Service Account
      #   kubernetes.core.k8s:
      #     api_version: apps/v1
      #     template: 'templates/openshift_4_resource_scc_to_user.yml'

      - name: Add PVC, ignore errors cause it was extended
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_persistentvolumeclaim.yml'
        ignore_errors: yes

      - name: Set Image reference, allowing variabel precedence
        set_fact:
          app_container_source_set_fact: "{{ app_container_source }}"
          
      - name: Add Deployment
        kubernetes.core.k8s:
          api_version: apps/v1
          template: 'templates/openshift_4_resource_deployment.yml'
        register: app_deployment
        until: app_deployment.result.spec.template.spec.containers[0].image == vars.app_container_source_set_fact
        retries: 5
        delay: 5

      - name: Waiting 5 seconds
        pause:
          seconds: 5
      
      - name: Get pod names
        kubernetes.core.k8s_info:
          api_version: v1
          kind: Pod
          namespace: "{{ app_namespace }}"
        register: pod_names
        timeout: 10
        retries: 3

      - name: Show pod name
        debug:
          msg: "Pod: {{ pod_names.resources[0].metadata.name }}"

      - name: Query disk Ansible example
        kubernetes.core.k8s_exec:
          namespace: "{{ app_namespace }}"
          pod: "{{ pod_names.resources[0].metadata.name }}"
          command: "dd if=/dev/urandom of=/dev/xvdb bs=64k count=10000"
        register: pod_exec
        until: pod_exec.rc == 0
        timeout: 10
        retries: 3

      - name: Display exec results
        debug:
          msg: "{{ pod_exec.stdout }}\n{{ pod_exec.stderr }}"


    - name: Extend Nginx app through Ansible with ceph-rbd and block mode
      vars:
        app_name: nginx-rbd
        app_namespace: test-nginx-ceph-rbd-block-ansible
        app_pvc_name: "{{ app_name }}-pvc"
        app_pvc_accessmode: ReadWriteMany # ReadWriteOnce, ReadWriteMany, ReadOnlyMany, based on storageClass & volumeMode
        app_pvc_volumeMode: Block # Generally Block or Filesystem
        app_pvc_size: 2Gi
        app_pvc_storageClassName: "{{ vars.openshift_data_foundation_config.storage_system_name }}-ceph-rbd"

      block:


      - name: Get PVC sizes pre change
        kubernetes.core.k8s_info:
          api_version: v1
          kind: PersistentVolumeClaim
          namespace: "{{ app_namespace }}"
        register: pvc_sizes_pre
        timeout: 10
        retries: 3

      - name: Extend PVC
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_persistentvolumeclaim.yml'

      - name: Waiting 5 seconds
        pause:
          seconds: 5

      - name: Get PVC sizes post change
        kubernetes.core.k8s_info:
          api_version: v1
          kind: PersistentVolumeClaim
          namespace: "{{ app_namespace }}"
        register: pvc_sizes_post
        timeout: 10
        retries: 3
        
      - name: Show PVC sizes
        debug:
          msg: "PVC: {{ pvc_sizes_pre.resources[0].metadata.name }} - 
            Pre {{ pvc_sizes_pre.resources[0].status.capacity.storage }} - 
            Post {{ pvc_sizes_post.resources[0].status.capacity.storage }}"


    - name: Nginx app through Ansible with ceph-rbd and Filesystem mode
      vars:
        app_name: nginx-rbd
        app_namespace: test-nginx-ceph-rbd-fs-ansible
        app_container_source: nginxinc/nginx-unprivileged:latest
        app_service_port: 80
        app_service_protocol: tcp
        app_container_port: 8080
        app_url: "http://{{ app_name }}-{{ app_namespace }}.apps.{{ openshift_cluster_name }}.{{ openshift_cluster_domain }}"
        app_replicas: 1 # Only ReadWriteOnce is supported by ceph-rbd & Filesystem mode, so no multiattach
        app_pvc_name: "{{ app_name }}-pvc"
        app_pvc_accessmode: ReadWriteOnce # ReadWriteOnce, ReadWriteMany, ReadOnlyMany, based on storageClass & volumeMode
        app_pvc_volumeMode: Filesystem # Generally Block or Filesystem
        app_pvc_size: 1Gi
        app_pvc_storageClassName: "{{ vars.openshift_data_foundation_config.storage_system_name }}-ceph-rbd"
        app_volumeMounts:
        - name: "{{ app_name }}-pv"
          mountPath: /usr/share/nginx
        - name: "{{ app_name }}-cm"
          mountPath: /usr/share/nginx/html
        app_volumes:
        - name: "{{ app_name }}-pv"
          persistentVolumeClaim:
            claimName: "{{ app_name }}-pvc"
        - name: "{{ app_name }}-cm"
          configMap:
            name: hello-world-html
        app_configmaps:
        - name: hello-world-html
          data:
          - key: index.html
            value: |
              <html>
                <head>
                </head>
                <body>
                  <h1>Hello World, through a ConfigMap!<h1>
                </body>
              </html>
          - key: index2.html
            value: |
              <html>
                <head>
                </head>
                <body>
                  <h1>Hello World, through a ConfigMap with multiple values!<h1>
                </body>
              </html>

      block:

      - name: Add namespace for Nginx with FS app through Ansible  
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_namespace.yml'

      - name: Add PVC, ignore errors cause it was extended
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_persistentvolumeclaim.yml'
        ignore_errors: yes

      - name: Set Image reference, allowing variabel precedence
        set_fact:
          app_container_source_set_fact: "{{ app_container_source }}"

      - name: Add ConfigMaps
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_configmap.yml'
        with_items: "{{ app_configmaps }}"
          
      - name: Add Deployment
        kubernetes.core.k8s:
          api_version: apps/v1
          template: 'templates/openshift_4_resource_deployment.yml'
        register: app_deployment
        until: app_deployment.result.spec.template.spec.containers[0].image == vars.app_container_source_set_fact
        retries: 5
        delay: 5

      - name: Add Service
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_service.yml'

      - name: Add Route
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_route.yml'

      - name: Waiting 5 seconds
        pause:
          seconds: 5

      - name: Query ToDo Ansible example
        include_tasks: 'tasks/query_url.yml'
        with_items:
        - url: "{{ app_url }}"
          text_to_find: 'Hello World'


    - name: Extend Nginx app through Ansible with ceph-rbd and filesystem mode
      vars:
        app_name: nginx-rbd
        app_namespace: test-nginx-ceph-rbd-fs-ansible
        app_pvc_name: "{{ app_name }}-pvc"
        app_pvc_accessmode: ReadWriteOnce # ReadWriteOnce, ReadWriteMany, ReadOnlyMany, based on storageClass & volumeMode
        app_pvc_volumeMode: Filesystem # Generally Block or Filesystem
        app_pvc_size: 2Gi
        app_pvc_storageClassName: "{{ vars.openshift_data_foundation_config.storage_system_name }}-ceph-rbd"

      block:

      - name: Get PVC sizes pre change
        kubernetes.core.k8s_info:
          api_version: v1
          kind: PersistentVolumeClaim
          namespace: "{{ app_namespace }}"
        register: pvc_sizes_pre
        timeout: 10
        retries: 3

      - name: Extend PVC
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_persistentvolumeclaim.yml'

      - name: Waiting 5 seconds
        pause:
          seconds: 5

      - name: Get PVC sizes post change
        kubernetes.core.k8s_info:
          api_version: v1
          kind: PersistentVolumeClaim
          namespace: "{{ app_namespace }}"
        register: pvc_sizes_post
        timeout: 10
        retries: 3
        
      - name: Show PVC sizes
        debug:
          msg: "PVC: {{ pvc_sizes_pre.resources[0].metadata.name }} - 
            Pre {{ pvc_sizes_pre.resources[0].status.capacity.storage }} - 
            Post {{ pvc_sizes_post.resources[0].status.capacity.storage }}"


    - name: Nginx app through Ansible with cephfs and Filesystem mode
      vars:
        app_name: nginx-fs
        app_namespace: test-nginx-cephfs-fs-ansible
        app_container_source: nginxinc/nginx-unprivileged:latest
        app_service_port: 80
        app_service_protocol: tcp
        app_container_port: 8080
        app_url: "http://{{ app_name }}-{{ app_namespace }}.apps.{{ openshift_cluster_name }}.{{ openshift_cluster_domain }}"
        app_replicas: 2
        app_pvc_name: "{{ app_name }}-pvc"
        app_pvc_accessmode: ReadWriteMany # ReadWriteOnce, ReadWriteMany, ReadOnlyMany, based on storageClass & volumeMode
        app_pvc_volumeMode: Filesystem # Generally Block or Filesystem
        app_pvc_size: 1Gi
        app_pvc_storageClassName: "{{ vars.openshift_data_foundation_config.storage_system_name }}-cephfs"
        app_volumeMounts:
        - name: "{{ app_name }}-pv"
          mountPath: /usr/share/nginx
        - name: "{{ app_name }}-cm"
          mountPath: /usr/share/nginx/html
        app_volumes:
        - name: "{{ app_name }}-pv"
          persistentVolumeClaim:
            claimName: "{{ app_name }}-pvc"
        - name: "{{ app_name }}-cm"
          configMap:
            name: hello-world-html
        app_configmaps:
        - name: hello-world-html
          data:
          - key: index.html
            value: |
              <html>
                <head>
                </head>
                <body>
                  <h1>Hello World, through a ConfigMap!<h1>
                </body>
              </html>
          - key: index2.html
            value: |
              <html>
                <head>
                </head>
                <body>
                  <h1>Hello World, through a ConfigMap with multiple values!<h1>
                </body>
              </html>

      block:

      - name: Add namespace for Nginx with FS app through Ansible  
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_namespace.yml'

      - name: Add PVC, ignore errors cause it was extended
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_persistentvolumeclaim.yml'
        ignore_errors: yes

      - name: Set Image reference, allowing variabel precedence
        set_fact:
          app_container_source_set_fact: "{{ app_container_source }}"

      - name: Add ConfigMaps
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_configmap.yml'
        with_items: "{{ app_configmaps }}"
          
      - name: Add Deployment
        kubernetes.core.k8s:
          api_version: apps/v1
          template: 'templates/openshift_4_resource_deployment.yml'
        register: app_deployment
        until: app_deployment.result.spec.template.spec.containers[0].image == vars.app_container_source_set_fact
        retries: 5
        delay: 5

      - name: Add Service
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_service.yml'

      - name: Add Route
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_route.yml'

      - name: Waiting 5 seconds
        pause:
          seconds: 5

      - name: Query ToDo Ansible example
        include_tasks: 'tasks/query_url.yml'
        with_items:
        - url: "{{ app_url }}"
          text_to_find: 'Hello World'


    - name: Extend Nginx app through Ansible with cephfs and filesystem mode
      vars:
        app_name: nginx-fs
        app_namespace: test-nginx-cephfs-fs-ansible
        app_pvc_name: "{{ app_name }}-pvc"
        app_pvc_accessmode: ReadWriteMany # ReadWriteOnce, ReadWriteMany, ReadOnlyMany, based on storageClass & volumeMode
        app_pvc_volumeMode: Filesystem # Generally Block or Filesystem
        app_pvc_size: 2Gi
        app_pvc_storageClassName: "{{ vars.openshift_data_foundation_config.storage_system_name }}-cephfs"

      block:

      - name: Get PVC sizes pre change
        kubernetes.core.k8s_info:
          api_version: v1
          kind: PersistentVolumeClaim
          namespace: "{{ app_namespace }}"
        register: pvc_sizes_pre
        timeout: 10
        retries: 3

      - name: Extend PVC
        kubernetes.core.k8s:
          state: present
          template: 'templates/openshift_4_resource_persistentvolumeclaim.yml'

      - name: Waiting 5 seconds
        pause:
          seconds: 5

      - name: Get PVC sizes post change
        kubernetes.core.k8s_info:
          api_version: v1
          kind: PersistentVolumeClaim
          namespace: "{{ app_namespace }}"
        register: pvc_sizes_post
        timeout: 10
        retries: 3
        
      - name: Show PVC sizes
        debug:
          msg: "PVC: {{ pvc_sizes_pre.resources[0].metadata.name }} - 
            Pre {{ pvc_sizes_pre.resources[0].status.capacity.storage }} - 
            Post {{ pvc_sizes_post.resources[0].status.capacity.storage }}"
